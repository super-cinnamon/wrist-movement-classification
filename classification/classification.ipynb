{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install scikit-learn torch xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = os.path.join(os.getcwd(), '..', \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = \"processed_dataset.csv\"\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd(), '..', \"data\")\n",
    "dataset_path = os.path.join(DATA_PATH, dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop(\"class\", axis=1), dataset[\"class\"], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search & training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': [1, 3, 5, 7],\n",
    "    'metric': ['minkowski', 'manhattan', 'cosine', 'haversine'],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid_search = GridSearchCV(KNeighborsClassifier(), knn_param_grid, cv=5)\n",
    "knn_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_knn_params = knn_grid_search.best_params_\n",
    "best_knn_model = knn_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model and hyperparametrs into files\n",
    "if not os.path.exists(os.path.join(MODELS_PATH, \"knn\")):\n",
    "    os.makedirs(os.path.join(MODELS_PATH, \"knn\"))\n",
    "with open(os.path.join(MODELS_PATH, \"knn\", 'best_params.json'), 'w') as f:\n",
    "    json.dump(best_knn_params, f, indent=4)\n",
    "\n",
    "joblib.dump(best_knn_model, os.path.join(MODELS_PATH, \"knn\", 'model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_param_grid = {\n",
    "    'solver': ['lbfgs', 'liblinear', 'newton-cholesky'],\n",
    "    'max_iter': [50, 100, 150, 200, 250, 300, 500],\n",
    "    'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    'C': [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 9.5, 10.0],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_grid_search = GridSearchCV(LogisticRegression(), logistic_regression_param_grid, cv=5)\n",
    "logistic_regression_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logreg_params = logistic_regression_grid_search.best_params_\n",
    "best_logreg_model = logistic_regression_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model and hyperparametrs into files\n",
    "if not os.path.exists(os.path.join(MODELS_PATH, \"logistic_regression\")):\n",
    "    os.makedirs(os.path.join(MODELS_PATH, \"logistic_regression\"))\n",
    "with open(os.path.join(MODELS_PATH, \"logistic_regression\", 'best_params.json'), 'w') as f:\n",
    "    json.dump(best_logreg_params, f, indent=4)\n",
    "\n",
    "joblib.dump(best_logreg_model, os.path.join(MODELS_PATH, \"logistic_regression\", 'model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_grid_search = GridSearchCV(GaussianNB(), bayes_param_grid, cv=5)\n",
    "bayes_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_bayes_params = bayes_grid_search.best_params_\n",
    "best_bayes_model = bayes_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model and hyperparametrs into files\n",
    "if not os.path.exists(os.path.join(MODELS_PATH, \"naive_bayes\")):\n",
    "    os.makedirs(os.path.join(MODELS_PATH, \"naive_bayes\"))\n",
    "with open(os.path.join(MODELS_PATH, \"naive_bayes\", 'best_params.json'), 'w') as f:\n",
    "    json.dump(best_bayes_params, f, indent=4)\n",
    "\n",
    "joblib.dump(best_bayes_model, os.path.join(MODELS_PATH, \"naive_bayes\", 'model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'C': [0.01, 0.1, 1, 10],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1, 10],\n",
    "    'coef0': [-1, 0, 1, 2, 3],\n",
    "    'shrinking': [False],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_grid_search = GridSearchCV(SVC(), svm_param_grid, cv=5)\n",
    "svm_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_svm_params = svm_grid_search.best_params_\n",
    "best_svm_model = svm_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model and hyperparametrs into files\n",
    "if not os.path.exists(os.path.join(MODELS_PATH, \"svm\")):\n",
    "    os.makedirs(os.path.join(MODELS_PATH, \"svm\"))\n",
    "with open(os.path.join(MODELS_PATH, \"svm\", 'best_params.json'), 'w') as f:\n",
    "    json.dump(best_svm_params, f, indent=4)\n",
    "\n",
    "joblib.dump(best_svm_model, os.path.join(MODELS_PATH, \"svm\", 'model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6, 7, 8],\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'min_weight_fraction_leaf': [0.01, 0.02, 0.03, 0.04, 0.05],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_grid_search = GridSearchCV(DecisionTreeClassifier(), decision_tree_param_grid, cv=5)\n",
    "decision_tree_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dt_params = decision_tree_grid_search.best_params_\n",
    "best_dt_model = decision_tree_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model and hyperparametrs into files\n",
    "if not os.path.exists(os.path.join(MODELS_PATH, \"decision_tree\")):\n",
    "    os.makedirs(os.path.join(MODELS_PATH, \"decision_tree\"))\n",
    "with open(os.path.join(MODELS_PATH, \"decision_tree\", 'best_params.json'), 'w') as f:\n",
    "    json.dump(best_dt_params, f, indent=4)\n",
    "\n",
    "joblib.dump(best_dt_model, os.path.join(MODELS_PATH, \"decision_tree\", 'model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_param_grid = {\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [None, 3, 5, 6, 7, 8],\n",
    "    'min_samples_split': [2, 4, 5, 7, 8],\n",
    "    'min_samples_leaf': [1, 2, 5, 7],\n",
    "    'min_weight_fraction_leaf': [0.01, 0.03, 0.05], \n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'n_estimators': [20, 50, 100, 150, 200],\n",
    "    'bootstrap': [False, True],\n",
    "    'warm_start': [False, True]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_grid_search = GridSearchCV(RandomForestClassifier(), random_forest_param_grid, cv=5)\n",
    "random_forest_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_params = random_forest_grid_search.best_params_\n",
    "best_rf_model = random_forest_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model and hyperparametrs into files\n",
    "if not os.path.exists(os.path.join(MODELS_PATH, \"random_forest\")):\n",
    "    os.makedirs(os.path.join(MODELS_PATH, \"random_forest\"))\n",
    "with open(os.path.join(MODELS_PATH, \"random_forest\", 'best_params.json'), 'w') as f:\n",
    "    json.dump(best_rf_params, f, indent=4)\n",
    "\n",
    "joblib.dump(best_rf_model, os.path.join(MODELS_PATH, \"random_forst\", 'model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 150, 200, 300],\n",
    "    'min_child_weight': [1, 2, 3, 4],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [3, 4, 5, 6, 7],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'scale_pos_weight': [1, 2, 3, 4],\n",
    "    'reg_alpha': [0, 0.1, 0.2, 0.3],\n",
    "    'reg_lambda': [0, 0.1, 0.2, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_grid_search = GridSearchCV(XGBClassifier(), xgboost_param_grid, cv=5)\n",
    "xgboost_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb_params = xgboost_grid_search.best_params_\n",
    "best_xgb_model = xgboost_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save best model and hyperparametrs into files\n",
    "if not os.path.exists(os.path.join(MODELS_PATH, \"xgboost\")):\n",
    "    os.makedirs(os.path.join(MODELS_PATH, \"xgboost\"))\n",
    "with open(os.path.join(MODELS_PATH, \"xgboost\", 'best_params.json'), 'w') as f:\n",
    "    json.dump(best_rf_params, f, indent=4)\n",
    "\n",
    "joblib.dump(best_rf_model, os.path.join(MODELS_PATH, \"xgboost\", 'model.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=32, output_size=1, activation='relu',\n",
    "                 optimizer='adam', batch_size=32, regularization=0.0001,\n",
    "                 epochs=100, lr=0.01, loss='hinge',\n",
    "                 report=True):\n",
    "        super(MultiLayerPerceptron, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size  # Default to 32 if not specified\n",
    "        self.output_size = output_size\n",
    "        self.activation = activation\n",
    "        self.optimizer_name = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.regularization = regularization\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.loss_name = loss\n",
    "        self.report = report\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, self.hidden_size)  # Input layer\n",
    "        self.fc2 = nn.Linear(self.hidden_size, self.hidden_size)  # Hidden layer\n",
    "        self.fc3 = nn.Linear(self.hidden_size, output_size)  # Output layer\n",
    "\n",
    "        # Activation functions\n",
    "        self.activation_dict = {\n",
    "            'relu': nn.ReLU(),\n",
    "            'leaky_relu': nn.LeakyReLU(),\n",
    "            'tanh': nn.Tanh(),\n",
    "            'swish': nn.SiLU(),\n",
    "            'gelu': nn.GELU(),\n",
    "            'selu': nn.SELU(),\n",
    "            'sigmoid': nn.Sigmoid(),\n",
    "        }\n",
    "        self.activation_fn = self.activation_dict.get(self.activation, nn.ReLU())\n",
    "\n",
    "        # Optimizers\n",
    "        self.optimizer_dict = {\n",
    "            'adam': optim.Adam,\n",
    "            'rmsprop': optim.RMSprop,\n",
    "            'sgd': optim.SGD\n",
    "        }\n",
    "        self.optimizer_fn = self.optimizer_dict.get(self.optimizer_name, optim.Adam)\n",
    "\n",
    "        # Loss functions\n",
    "        self.loss_dict = {\n",
    "            'mse': nn.MSELoss(),\n",
    "            'hinge': nn.HingeEmbeddingLoss(),\n",
    "            'log': nn.BCEWithLogitsLoss(),\n",
    "        }\n",
    "        self.loss_fn = self.loss_dict.get(self.loss_name, nn.BCEWithLogitsLoss())\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.activation_fn(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.activation_fn(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.activation_dict['sigmoid'](out)\n",
    "        return out\n",
    "\n",
    "    def train_model(self, train_loader, val_loader=None):\n",
    "        optimizer = self.optimizer_fn(self.parameters(), lr=self.lr, weight_decay=self.regularization)\n",
    "        criterion = self.loss_fn\n",
    "\n",
    "        best_f1 = 0\n",
    "        for epoch in range(self.epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "            if val_loader:\n",
    "                f1 = self.evaluate(val_loader)\n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                if self.report:\n",
    "                    print(f'Epoch {epoch+1}/{self.epochs}, Loss: {epoch_loss:.4f}, F1: {f1:.2f}%')\n",
    "            else:\n",
    "                if self.report:\n",
    "                    print(f'Epoch {epoch+1}/{self.epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "        return best_f1\n",
    "\n",
    "    def evaluate(self, dataloader):\n",
    "        self.eval()\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in dataloader:\n",
    "                outputs = self(inputs)\n",
    "                predicted = (outputs > 0.5).float()\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        f1 = f1_score(all_labels, all_preds, average='binary') * 100\n",
    "        return f1\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        This function takes a list of floats as input and returns a single float between 0 and 1.\n",
    "        \"\"\"\n",
    "        if len(data) != self.input_size:\n",
    "            raise ValueError(f\"Input data must be a list of {self.input_size} floats.\")\n",
    "\n",
    "        # Convert data to a tensor\n",
    "        data_tensor = torch.tensor(data, dtype=torch.float).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # Forward pass through the network\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(data_tensor)\n",
    "\n",
    "        return output.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(X, y, batch_size):\n",
    "    X = torch.tensor(X.values, dtype=torch.float32)\n",
    "    y = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new validation subset from train split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 15 \n",
    "\n",
    "# Hyperparameter grid\n",
    "hidden_sizes = [4, 8, 16, 32, 64]\n",
    "activations = ['relu', 'leaky_relu', 'tanh', 'swish', 'gelu', 'selu']\n",
    "optimizers = ['adam', 'rmsprop', 'sgd']\n",
    "batch_sizes = [4, 8, 16, 32]\n",
    "regularizations = [0.0001, 0.001, 0.01]\n",
    "epochs_list = [5, 10, 20, 30, 50, 80, 100]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "losses = ['mse', 'hinge', 'log']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_PATH = os.path.join(MODELS_PATH, \"mlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Create all combinations\n",
    "hyperparameter_combinations = list(itertools.product(\n",
    "    hidden_sizes,\n",
    "    activations,\n",
    "    optimizers,\n",
    "    batch_sizes,\n",
    "    regularizations,\n",
    "    epochs_list,\n",
    "    learning_rates,\n",
    "    losses\n",
    "))\n",
    "\n",
    "print(f\"Total hyperparameter combinations: {len(hyperparameter_combinations)}\")\n",
    "\n",
    "# To store results\n",
    "results = []\n",
    "\n",
    "# Iterate through each combination\n",
    "for idx, (hidden_size, activation, optimizer_name, batch_size,\n",
    "          regularization, epochs, lr, loss_name) in enumerate(hyperparameter_combinations, 1):\n",
    "\n",
    "    print(f\"\\nRunning combination {idx}/{len(hyperparameter_combinations)}:\")\n",
    "    print(f\"Hidden Size: {hidden_size}, Activation: {activation}, Optimizer: {optimizer_name}, \"\n",
    "          f\"Batch Size: {batch_size}, Regularization: {regularization}, Epochs: {epochs}, \"\n",
    "          f\"Learning Rate: {lr}, Loss: {loss_name}\")\n",
    "\n",
    "    # Create DataLoaders with the current batch size\n",
    "    train_loader = data_loader(X_train, y_train, batch_size)\n",
    "    val_loader = data_loader(X_val, y_val, batch_size)\n",
    "\n",
    "    # Initialize the model with current hyperparameters\n",
    "    model = MultiLayerPerceptron(\n",
    "        input_size=input_size,\n",
    "        hidden_size=hidden_size,\n",
    "        activation=activation,\n",
    "        optimizer=optimizer_name,\n",
    "        batch_size=batch_size,\n",
    "        regularization=regularization,\n",
    "        epochs=epochs,\n",
    "        lr=lr,\n",
    "        loss=loss_name,\n",
    "        report=False\n",
    "    )\n",
    "\n",
    "    # Train the model and get the best F1 score\n",
    "    try:\n",
    "        best_f1 = model.train_model(train_loader, val_loader)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        best_f1 = None\n",
    "\n",
    "    # Record the results\n",
    "    results.append({\n",
    "        'hidden_size': hidden_size,\n",
    "        'activation': activation,\n",
    "        'optimizer': optimizer_name,\n",
    "        'batch_size': batch_size,\n",
    "        'regularization': regularization,\n",
    "        'epochs': epochs,\n",
    "        'learning_rate': lr,\n",
    "        'loss': loss_name,\n",
    "        'best_f1': best_f1\n",
    "    })\n",
    "\n",
    "    # Optional: Save intermediate results to prevent data loss in case of interruptions\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(os.path.join(MLP_PATH, 'grid_search_results.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Drop combinations that failed (if any)\n",
    "results_df = results_df.dropna(subset=['best_f1'])\n",
    "\n",
    "# Find the best hyperparameter set\n",
    "best_result = results_df.loc[results_df['best_f1'].idxmax()]\n",
    "\n",
    "print(\"\\nBest Hyperparameter Combination:\")\n",
    "print(best_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(os.path.join(MODELS_PATH, \"knn\", \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = {\n",
    "    \"f1_score\": f1,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(os.path.join(MODELS_PATH, \"logistic_regression\", \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = {\n",
    "    \"f1_score\": f1,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(os.path.join(MODELS_PATH, \"naive_bayes\", \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = {\n",
    "    \"f1_score\": f1,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(os.path.join(MODELS_PATH, \"svm\", \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = {\n",
    "    \"f1_score\": f1,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(os.path.join(MODELS_PATH, \"decision_tree\", \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = {\n",
    "    \"f1_score\": f1,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(os.path.join(MODELS_PATH, \"random_forest\", \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = {\n",
    "    \"f1_score\": f1,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(os.path.join(MODELS_PATH, \"xgboost\", \"model.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "results = {\n",
    "    \"f1_score\": f1,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP (ANN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
